{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " LSTUR: Neural News Recommendation with Long- and Short-term User Representations.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPzDE2dFvGDf2qC21e1nmRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wendy60/Hybrid-recommender-system/blob/second-submit/LSTUR_Neural_News_Recommendation_with_Long_and_Short_term_User_Representations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I use an open source project from github, so I need to declare the copyright for each model. I use the MIND public dataset and the python package -- recommenders from microsoft.\n",
        "\n",
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {
        "id": "2rmhFFoXctB6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs94MKpIeDg0"
      },
      "source": [
        "# **Global settings and imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4yQ1b86bGp4",
        "outputId": "81ce6cbd-1b42-40be-c350-49f8b05db772"
      },
      "source": [
        "pip install recommenders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting recommenders\n",
            "  Downloading recommenders-0.7.0-py3-none-manylinux1_x86_64.whl (314 kB)\n",
            "\u001b[K     |████████████████████████████████| 314 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting pydocumentdb>=2.3.3<3\n",
            "  Downloading pydocumentdb-2.3.5-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lightgbm>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (2.2.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.31.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (4.62.3)\n",
            "Collecting cornac<2,>=1.1.2\n",
            "  Downloading cornac-1.14.1-cp37-cp37m-manylinux1_x86_64.whl (12.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 63.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2<3,>=2 in /usr/local/lib/python3.7/dist-packages (from recommenders) (2.11.3)\n",
            "Requirement already satisfied: numba<1,>=0.38.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (0.51.2)\n",
            "Requirement already satisfied: pandas<2,>1.0.3 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.1.5)\n",
            "Collecting memory-profiler<1,>=0.54.0\n",
            "  Downloading memory_profiler-0.58.0.tar.gz (36 kB)\n",
            "Collecting scikit-surprise<=1.1.1,>=0.19.1\n",
            "  Downloading scikit-surprise-1.1.1.tar.gz (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bottleneck<2,>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.3.2)\n",
            "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.4.1)\n",
            "Requirement already satisfied: seaborn<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from recommenders) (0.11.2)\n",
            "Collecting transformers<5,>=2.5.0\n",
            "  Downloading transformers-4.12.4-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 53.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6,>=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 65.1 MB/s \n",
            "\u001b[?25hCollecting scikit-learn<1,>=0.22.1\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 87 kB/s \n",
            "\u001b[?25hCollecting lightfm<2,>=1.15\n",
            "  Downloading lightfm-1.16.tar.gz (310 kB)\n",
            "\u001b[K     |████████████████████████████████| 310 kB 60.0 MB/s \n",
            "\u001b[?25hCollecting nltk<4,>=3.4\n",
            "  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 68.5 MB/s \n",
            "\u001b[?25hCollecting category-encoders<2,>=1.3.0\n",
            "  Downloading category_encoders-1.3.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib<4,>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from recommenders) (3.2.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from recommenders) (1.19.5)\n",
            "Collecting pymanopt<1,>=0.2.5\n",
            "  Downloading pymanopt-0.2.5-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from recommenders) (2.23.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders<2,>=1.3.0->recommenders) (0.5.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from category-encoders<2,>=1.3.0->recommenders) (0.10.2)\n",
            "Collecting powerlaw\n",
            "  Downloading powerlaw-1.5-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3,>=2->recommenders) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4,>=2.2.2->recommenders) (2.8.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler<1,>=0.54.0->recommenders) (5.4.8)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->recommenders) (2021.11.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->recommenders) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4,>=3.4->recommenders) (7.1.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<1,>=0.38.1->recommenders) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba<1,>=0.38.1->recommenders) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>1.0.3->recommenders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.4.1->category-encoders<2,>=1.3.0->recommenders) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->recommenders) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1,>=0.22.1->recommenders) (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (3.3.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (21.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5,>=2.5.0->recommenders) (4.8.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 57.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers<5,>=2.5.0->recommenders) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5,>=2.5.0->recommenders) (3.6.0)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.7/dist-packages (from powerlaw->cornac<2,>=1.1.2->recommenders) (1.2.1)\n",
            "Building wheels for collected packages: lightfm, memory-profiler, scikit-surprise\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705372 sha256=2a0fccf551b818247d53d1585c3d58e81964277fa2607d8368f41aaa896bf478\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/56/28/5772a3bd3413d65f03aa452190b00898b680b10028a1021914\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-py3-none-any.whl size=30190 sha256=22c654fdcc46ca391e7927ca42b062beb85076d388bd1b87399f67a9c447eb0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/19/d5/8cad06661aec65a04a0d6785b1a5ad035cb645b1772a4a0882\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1619420 sha256=c59a652acca6141e9513bcde7eae99432a7a295c21f2c15598bfa21b1c470368\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/44/74/b498c42be47b2406bd27994e16c5188e337c657025ab400c1c\n",
            "Successfully built lightfm memory-profiler scikit-surprise\n",
            "Installing collected packages: pyyaml, tokenizers, scikit-learn, sacremoses, powerlaw, huggingface-hub, transformers, scikit-surprise, pymanopt, pydocumentdb, nltk, memory-profiler, lightfm, cornac, category-encoders, recommenders\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed category-encoders-1.3.0 cornac-1.14.1 huggingface-hub-0.1.2 lightfm-1.16 memory-profiler-0.58.0 nltk-3.6.5 powerlaw-1.5 pydocumentdb-2.3.5 pymanopt-0.2.5 pyyaml-5.4.1 recommenders-0.7.0 sacremoses-0.0.46 scikit-learn-0.24.2 scikit-surprise-1.1.1 tokenizers-0.10.3 transformers-4.12.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfF3dFI9bgkY",
        "outputId": "54c20239-ca1b-4bc6-eebb-874440f53a9e"
      },
      "source": [
        "pip install tensorflow-gpu==1.15.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu==1.15.2\n",
            "  Downloading tensorflow_gpu-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (410.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 410.9 MB 12 kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 21.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.13.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.37.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.41.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (4.8.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.10.0.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=b2e93466765df35b427564703decc90b445fa990926ef8f92e7c6222e69af44e\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.7.0 requires tensorboard~=2.6, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.7.0 requires tensorflow-estimator<2.8,~=2.7.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.14.1 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M80vQFQxaipZ",
        "outputId": "123ce7c4-17a1-437a-d425-78bddadd847a"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from tempfile import TemporaryDirectory\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
        "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
        "from recommenders.models.newsrec.models.lstur import LSTURModel\n",
        "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
        "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
        "\n",
        "print(\"System version: {}\".format(sys.version))\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System version: 3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "Tensorflow version: 1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqgcApDLeLkR"
      },
      "source": [
        "# **Prepare Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n6TEFO5a3vV"
      },
      "source": [
        "epochs = 5\n",
        "seed = 40\n",
        "batch_size = 32\n",
        "\n",
        "# Options: demo, small, large\n",
        "#MIND_type = 'demo'\n",
        "MIND_type = 'small'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78dHR5IeTDz"
      },
      "source": [
        "# **Download and load data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLbrStHsb6It",
        "outputId": "f0701e88-06a3-4d43-9372-705a6cbb500c"
      },
      "source": [
        "tmpdir = TemporaryDirectory()\n",
        "data_path = tmpdir.name\n",
        "\n",
        "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
        "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
        "\n",
        "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
        "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
        "\n",
        "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
        "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
        "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
        "## yaml file is a configuration file\n",
        "yaml_file = os.path.join(data_path, \"utils\", r'lstur.yaml')\n",
        "\n",
        "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
        "\n",
        "if not os.path.exists(train_news_file):\n",
        "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
        "    \n",
        "if not os.path.exists(valid_news_file):\n",
        "    download_deeprec_resources(mind_url, \\\n",
        "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
        "if not os.path.exists(yaml_file):\n",
        "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
        "                               os.path.join(data_path, 'utils'), mind_utils)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17.0k/17.0k [00:00<00:00, 30.1kKB/s]\n",
            "100%|██████████| 9.84k/9.84k [00:00<00:00, 21.5kKB/s]\n",
            "100%|██████████| 95.0k/95.0k [00:02<00:00, 42.9kKB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQdIFlDneZY9"
      },
      "source": [
        "\n",
        "# **Create hyper-parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0hGVRqNb9wD",
        "outputId": "1524df6f-7fb5-4c3a-cebb-7eac14f548b9"
      },
      "source": [
        "hparams = prepare_hparams(yaml_file, \n",
        "                          wordEmb_file=wordEmb_file,\n",
        "                          wordDict_file=wordDict_file, \n",
        "                          userDict_file=userDict_file,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=epochs)\n",
        "print(hparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data_format=news,iterator_type=None,support_quick_scoring=True,wordEmb_file=/tmp/tmp2e6_vy6e/utils/embedding.npy,wordDict_file=/tmp/tmp2e6_vy6e/utils/word_dict.pkl,userDict_file=/tmp/tmp2e6_vy6e/utils/uid2index.pkl,vertDict_file=None,subvertDict_file=None,title_size=30,body_size=None,word_emb_dim=300,word_size=None,user_num=None,vert_num=None,subvert_num=None,his_size=50,npratio=4,dropout=0.2,attention_hidden_dim=200,head_num=4,head_dim=100,cnn_activation=relu,dense_activation=None,filter_num=400,window_size=3,vert_emb_dim=100,subvert_emb_dim=100,gru_unit=400,type=ini,user_emb_dim=50,learning_rate=0.0001,loss=cross_entropy_loss,optimizer=adam,epochs=5,batch_size=32,show_step=100000,metrics=['group_auc', 'mean_mrr', 'ndcg@5;10']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8E0YQHYcG2f"
      },
      "source": [
        "iterator = MINDIterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZvoyZnRefQE"
      },
      "source": [
        "# **Train the LSTUR model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8VAWghicKMe",
        "outputId": "d139684e-0742-4eaf-f67e-5c527056d697"
      },
      "source": [
        "model = LSTURModel(hparams, iterator, seed=seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"conv1d/Relu:0\", shape=(?, 30, 400), dtype=float32)\n",
            "Tensor(\"att_layer2/Sum_1:0\", shape=(?, 400), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SSBHmENcNRI",
        "outputId": "0c949574-fe5a-4353-bb38-37113a9b82ff"
      },
      "source": [
        "\n",
        "print(model.run_eval(valid_news_file, valid_behaviors_file))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1326it [00:01, 704.32it/s]\n",
            "2286it [00:55, 41.24it/s]\n",
            "73152it [00:09, 7440.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'group_auc': 0.6438, 'mean_mrr': 0.2928, 'ndcg@5': 0.3229, 'ndcg@10': 0.3897}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "06xaTLEQcR32",
        "outputId": "b50dd929-5c0c-4cf5-fa39-f7022c5e51a9"
      },
      "source": [
        "%%time\n",
        "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [13:59,  8.79it/s]\n",
            "1326it [00:01, 700.77it/s]\n",
            "2286it [00:56, 40.81it/s]\n",
            "73152it [00:09, 7344.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 1\n",
            "train info: logloss loss:1.2936728832410533\n",
            "eval info: group_auc:0.66, mean_mrr:0.3071, ndcg@10:0.4036, ndcg@5:0.3406\n",
            "at epoch 1 , train time: 839.8 eval time: 133.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [14:01,  8.78it/s]\n",
            "1326it [00:01, 710.20it/s]\n",
            "2286it [00:56, 40.74it/s]\n",
            "73152it [00:10, 6930.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 2\n",
            "train info: logloss loss:1.269264179760287\n",
            "eval info: group_auc:0.6636, mean_mrr:0.3117, ndcg@10:0.4083, ndcg@5:0.3441\n",
            "at epoch 2 , train time: 841.6 eval time: 134.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [14:03,  8.76it/s]\n",
            "1326it [00:01, 722.20it/s]\n",
            "2286it [00:56, 40.63it/s]\n",
            "73152it [00:10, 7201.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 3\n",
            "train info: logloss loss:1.2476109264989936\n",
            "eval info: group_auc:0.673, mean_mrr:0.3218, ndcg@10:0.4183, ndcg@5:0.3559\n",
            "at epoch 3 , train time: 843.1 eval time: 133.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [13:57,  8.82it/s]\n",
            "1326it [00:01, 714.95it/s]\n",
            "2286it [00:56, 40.36it/s]\n",
            "73152it [00:10, 7184.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 4\n",
            "train info: logloss loss:1.2256476001754997\n",
            "eval info: group_auc:0.6664, mean_mrr:0.3164, ndcg@10:0.412, ndcg@5:0.3483\n",
            "at epoch 4 , train time: 837.4 eval time: 134.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7386it [13:58,  8.81it/s]\n",
            "1326it [00:01, 718.76it/s]\n",
            "2286it [00:55, 41.07it/s]\n",
            "73152it [00:09, 7532.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "at epoch 5\n",
            "train info: logloss loss:1.19740165509798\n",
            "eval info: group_auc:0.664, mean_mrr:0.3153, ndcg@10:0.4116, ndcg@5:0.3481\n",
            "at epoch 5 , train time: 838.8 eval time: 131.1\n",
            "CPU times: user 1h 37min 19s, sys: 5min 51s, total: 1h 43min 10s\n",
            "Wall time: 1h 21min 6s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<recommenders.models.newsrec.models.lstur.LSTURModel at 0x7f2cfce507d0>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHEbkGO3ciDC",
        "outputId": "1b5543d5-c647-4ed4-a56c-e2cff74b864a"
      },
      "source": [
        "%%time\n",
        "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
        "print(res_syn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "586it [00:01, 535.29it/s]\n",
            "236it [00:07, 31.44it/s]\n",
            "7538it [00:01, 5255.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'group_auc': 0.6428, 'mean_mrr': 0.2985, 'ndcg@5': 0.3314, 'ndcg@10': 0.3929}\n",
            "CPU times: user 21.1 s, sys: 2.81 s, total: 23.9 s\n",
            "Wall time: 19 s\n"
          ]
        }
      ]
    }
  ]
}